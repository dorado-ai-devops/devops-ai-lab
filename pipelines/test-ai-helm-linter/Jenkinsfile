pipeline {
  agent {
    docker {
      image 'alpine/helm:3.12.3'
    }
  }

  parameters {
    choice(
      name: 'MODELO_IA',
      choices: ['openai', 'ollama'],
      description: 'Selecciona el motor de IA para linting de Helm Charts'
    )
  }

  environment {
    OPENAI_API_KEY = credentials('OPENAI_API_KEY')
  }

  stages {
    stage('Lint Helm Chart con IA') {
      steps {
        script {
          def chartPath = "./charts/example"
          def chartDest = "packaged_chart"
          sh "mkdir -p ${chartDest}"

          def chartTgz = sh(
            script: "helm package ${chartPath} --destination ${chartDest} | awk '{print \$NF}'",
            returnStdout: true
          ).trim()

          if (!chartTgz || !fileExists(chartTgz)) {
            error "El archivo empaquetado ${chartTgz} no se ha generado correctamente."
          }

          echo "Enviando archivo: ${chartTgz}"

          def curlCommand = """
            curl -X POST http://helm-linter-service.devops-ai.svc.cluster.local:80/lint-chart \
              -F "chart=@${chartTgz}" \
              -F "mode=${params.MODELO_IA}"
          """.stripIndent().trim()

          if (params.MODELO_IA == 'openai') {
            curlCommand += " -H \"Authorization: Bearer ${OPENAI_API_KEY}\""
          }

          def response = sh(script: curlCommand, returnStdout: true).trim()
          echo "Respuesta del Helm Linter IA (${params.MODELO_IA}):"
          echo "${response}"
        }
      }
    }
  }
}
